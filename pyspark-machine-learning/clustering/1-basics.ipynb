{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    master('local').\\\n",
    "    appName('clustering-basics').\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format('libsvm').\\\n",
    "    load('D:/learn-ab/learning-PySpark/sample-data/sample-kmeans-data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|           (3,[],[])|\n",
      "|  1.0|(3,[0,1,2],[0.1,0...|\n",
      "|  2.0|(3,[0,1,2],[0.2,0...|\n",
      "|  3.0|(3,[0,1,2],[9.0,9...|\n",
      "|  4.0|(3,[0,1,2],[9.1,9...|\n",
      "|  5.0|(3,[0,1,2],[9.2,9...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|           (3,[],[])|\n",
      "|(3,[0,1,2],[0.1,0...|\n",
      "|(3,[0,1,2],[0.2,0...|\n",
      "|(3,[0,1,2],[9.0,9...|\n",
      "|(3,[0,1,2],[9.1,9...|\n",
      "|(3,[0,1,2],[9.2,9...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = data.select('features')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfeaturesCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpredictionCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minitMode\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'k-means||'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minitSteps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmaxIter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdistanceMeasure\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mweightCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msolver\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmaxBlockSizeInMB\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "K-means clustering with a k-means++ like initialization mode\n",
      "(the k-means|| algorithm by Bahmani et al).\n",
      "\n",
      ".. versionadded:: 1.5.0\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from pyspark.ml.linalg import Vectors\n",
      ">>> data = [(Vectors.dense([0.0, 0.0]), 2.0), (Vectors.dense([1.0, 1.0]), 2.0),\n",
      "...         (Vectors.dense([9.0, 8.0]), 2.0), (Vectors.dense([8.0, 9.0]), 2.0)]\n",
      ">>> df = spark.createDataFrame(data, [\"features\", \"weighCol\"])\n",
      ">>> kmeans = KMeans(k=2)\n",
      ">>> kmeans.setSeed(1)\n",
      "KMeans...\n",
      ">>> kmeans.setWeightCol(\"weighCol\")\n",
      "KMeans...\n",
      ">>> kmeans.setMaxIter(10)\n",
      "KMeans...\n",
      ">>> kmeans.getMaxIter()\n",
      "10\n",
      ">>> kmeans.clear(kmeans.maxIter)\n",
      ">>> kmeans.getSolver()\n",
      "'auto'\n",
      ">>> model = kmeans.fit(df)\n",
      ">>> model.getMaxBlockSizeInMB()\n",
      "0.0\n",
      ">>> model.getDistanceMeasure()\n",
      "'euclidean'\n",
      ">>> model.setPredictionCol(\"newPrediction\")\n",
      "KMeansModel...\n",
      ">>> model.predict(df.head().features)\n",
      "0\n",
      ">>> centers = model.clusterCenters()\n",
      ">>> len(centers)\n",
      "2\n",
      ">>> transformed = model.transform(df).select(\"features\", \"newPrediction\")\n",
      ">>> rows = transformed.collect()\n",
      ">>> rows[0].newPrediction == rows[1].newPrediction\n",
      "True\n",
      ">>> rows[2].newPrediction == rows[3].newPrediction\n",
      "True\n",
      ">>> model.hasSummary\n",
      "True\n",
      ">>> summary = model.summary\n",
      ">>> summary.k\n",
      "2\n",
      ">>> summary.clusterSizes\n",
      "[2, 2]\n",
      ">>> summary.trainingCost\n",
      "4.0\n",
      ">>> kmeans_path = temp_path + \"/kmeans\"\n",
      ">>> kmeans.save(kmeans_path)\n",
      ">>> kmeans2 = KMeans.load(kmeans_path)\n",
      ">>> kmeans2.getK()\n",
      "2\n",
      ">>> model_path = temp_path + \"/kmeans_model\"\n",
      ">>> model.save(model_path)\n",
      ">>> model2 = KMeansModel.load(model_path)\n",
      ">>> model2.hasSummary\n",
      "False\n",
      ">>> model.clusterCenters()[0] == model2.clusterCenters()[0]\n",
      "array([ True,  True], dtype=bool)\n",
      ">>> model.clusterCenters()[1] == model2.clusterCenters()[1]\n",
      "array([ True,  True], dtype=bool)\n",
      ">>> model.transform(df).take(1) == model2.transform(df).take(1)\n",
      "True\n",
      "\u001b[1;31mInit docstring:\u001b[0m __init__(self, \\*, featuresCol=\"features\", predictionCol=\"prediction\", k=2,                  initMode=\"k-means||\", initSteps=2, tol=1e-4, maxIter=20, seed=None,                  distanceMeasure=\"euclidean\", weightCol=None, solver=\"auto\",                  maxBlockSizeInMB=0.0)\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\learn-ab\\learning-pyspark\\.env\\lib\\site-packages\\pyspark\\ml\\clustering.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans().setK(2).setSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = kmeans.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pred = kmeans_model.transform(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|           (3,[],[])|         1|\n",
      "|(3,[0,1,2],[0.1,0...|         1|\n",
      "|(3,[0,1,2],[0.2,0...|         1|\n",
      "|(3,[0,1,2],[9.0,9...|         0|\n",
      "|(3,[0,1,2],[9.1,9...|         0|\n",
      "|(3,[0,1,2],[9.2,9...|         0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9.1, 9.1, 9.1]), array([0.1, 0.1, 0.1])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centers = kmeans_model.clusterCenters()\n",
    "cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mClusteringEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpredictionCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfeaturesCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetricName\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'ClusteringEvaluatorMetricType'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'silhouette'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdistanceMeasure\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'squaredEuclidean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mweightCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Evaluator for Clustering results, which expects two input\n",
      "columns: prediction and features. The metric computes the Silhouette\n",
      "measure using the squared Euclidean distance.\n",
      "\n",
      "The Silhouette is a measure for the validation of the consistency\n",
      "within clusters. It ranges between 1 and -1, where a value close to\n",
      "1 means that the points in a cluster are close to the other points\n",
      "in the same cluster and far from the points of the other clusters.\n",
      "\n",
      ".. versionadded:: 2.3.0\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from pyspark.ml.linalg import Vectors\n",
      ">>> featureAndPredictions = map(lambda x: (Vectors.dense(x[0]), x[1]),\n",
      "...     [([0.0, 0.5], 0.0), ([0.5, 0.0], 0.0), ([10.0, 11.0], 1.0),\n",
      "...     ([10.5, 11.5], 1.0), ([1.0, 1.0], 0.0), ([8.0, 6.0], 1.0)])\n",
      ">>> dataset = spark.createDataFrame(featureAndPredictions, [\"features\", \"prediction\"])\n",
      "...\n",
      ">>> evaluator = ClusteringEvaluator()\n",
      ">>> evaluator.setPredictionCol(\"prediction\")\n",
      "ClusteringEvaluator...\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.9079...\n",
      ">>> featureAndPredictionsWithWeight = map(lambda x: (Vectors.dense(x[0]), x[1], x[2]),\n",
      "...     [([0.0, 0.5], 0.0, 2.5), ([0.5, 0.0], 0.0, 2.5), ([10.0, 11.0], 1.0, 2.5),\n",
      "...     ([10.5, 11.5], 1.0, 2.5), ([1.0, 1.0], 0.0, 2.5), ([8.0, 6.0], 1.0, 2.5)])\n",
      ">>> dataset = spark.createDataFrame(\n",
      "...     featureAndPredictionsWithWeight, [\"features\", \"prediction\", \"weight\"])\n",
      ">>> evaluator = ClusteringEvaluator()\n",
      ">>> evaluator.setPredictionCol(\"prediction\")\n",
      "ClusteringEvaluator...\n",
      ">>> evaluator.setWeightCol(\"weight\")\n",
      "ClusteringEvaluator...\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.9079...\n",
      ">>> ce_path = temp_path + \"/ce\"\n",
      ">>> evaluator.save(ce_path)\n",
      ">>> evaluator2 = ClusteringEvaluator.load(ce_path)\n",
      ">>> str(evaluator2.getPredictionCol())\n",
      "'prediction'\n",
      "\u001b[1;31mInit docstring:\u001b[0m __init__(self, \\*, predictionCol=\"prediction\", featuresCol=\"features\",                  metricName=\"silhouette\", distanceMeasure=\"squaredEuclidean\", weightCol=None)\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\learn-ab\\learning-pyspark\\.env\\lib\\site-packages\\pyspark\\ml\\evaluation.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_eval = ClusteringEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance :0.9997530305375207\n"
     ]
    }
   ],
   "source": [
    "silhouette = kmeans_eval.evaluate(kmeans_pred)\n",
    "print(f'Silhouette with squared euclidean distance :{silhouette}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Results : \n",
      "\n",
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|           (3,[],[])|         1|\n",
      "|(3,[0,1,2],[0.1,0...|         1|\n",
      "|(3,[0,1,2],[0.2,0...|         2|\n",
      "|(3,[0,1,2],[9.0,9...|         0|\n",
      "|(3,[0,1,2],[9.1,9...|         0|\n",
      "|(3,[0,1,2],[9.2,9...|         0|\n",
      "+--------------------+----------+\n",
      "\n",
      "Cluster Centers : \n",
      "{cluster_centers}\n",
      "Silhouette with squared euclidean distance :0.6248737134600261\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans().setK(3).setSeed(1)\n",
    "kmeans_model = kmeans.fit(final_data)\n",
    "kmeans_pred = kmeans_model.transform(final_data)\n",
    "print('Clustering Results : \\n')\n",
    "kmeans_pred.show()\n",
    "cluster_centers = kmeans_model.clusterCenters()\n",
    "print('Cluster Centers : \\n{cluster_centers}')\n",
    "silhouette = kmeans_eval.evaluate(kmeans_pred)\n",
    "print(f'Silhouette with squared euclidean distance :{silhouette}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Results : \n",
      "\n",
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|           (3,[],[])|         1|\n",
      "|(3,[0,1,2],[0.1,0...|         1|\n",
      "|(3,[0,1,2],[0.2,0...|         2|\n",
      "|(3,[0,1,2],[9.0,9...|         0|\n",
      "|(3,[0,1,2],[9.1,9...|         0|\n",
      "|(3,[0,1,2],[9.2,9...|         3|\n",
      "+--------------------+----------+\n",
      "\n",
      "Cluster Centers : \n",
      "{cluster_centers}\n",
      "Silhouette with squared euclidean distance :0.25000000000146066\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans().setK(4).setSeed(1)\n",
    "kmeans_model = kmeans.fit(final_data)\n",
    "kmeans_pred = kmeans_model.transform(final_data)\n",
    "print('Clustering Results : \\n')\n",
    "kmeans_pred.show()\n",
    "cluster_centers = kmeans_model.clusterCenters()\n",
    "print('Cluster Centers : \\n{cluster_centers}')\n",
    "silhouette = kmeans_eval.evaluate(kmeans_pred)\n",
    "print(f'Silhouette with squared euclidean distance :{silhouette}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Results : \n",
      "\n",
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|           (3,[],[])|         1|\n",
      "|(3,[0,1,2],[0.1,0...|         1|\n",
      "|(3,[0,1,2],[0.2,0...|         2|\n",
      "|(3,[0,1,2],[9.0,9...|         0|\n",
      "|(3,[0,1,2],[9.1,9...|         4|\n",
      "|(3,[0,1,2],[9.2,9...|         3|\n",
      "+--------------------+----------+\n",
      "\n",
      "Cluster Centers : \n",
      "{cluster_centers}\n",
      "Silhouette with squared euclidean distance :0.12500000000000008\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans().setK(5).setSeed(1)\n",
    "kmeans_model = kmeans.fit(final_data)\n",
    "kmeans_pred = kmeans_model.transform(final_data)\n",
    "print('Clustering Results : \\n')\n",
    "kmeans_pred.show()\n",
    "cluster_centers = kmeans_model.clusterCenters()\n",
    "print('Cluster Centers : \\n{cluster_centers}')\n",
    "silhouette = kmeans_eval.evaluate(kmeans_pred)\n",
    "print(f'Silhouette with squared euclidean distance :{silhouette}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Results : \n",
      "\n",
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|           (3,[],[])|         1|\n",
      "|(3,[0,1,2],[0.1,0...|         2|\n",
      "|(3,[0,1,2],[0.2,0...|         3|\n",
      "|(3,[0,1,2],[9.0,9...|         4|\n",
      "|(3,[0,1,2],[9.1,9...|         5|\n",
      "|(3,[0,1,2],[9.2,9...|         0|\n",
      "+--------------------+----------+\n",
      "\n",
      "Cluster Centers : \n",
      "{cluster_centers}\n",
      "Silhouette with squared euclidean distance :0.0\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans().setK(6).setSeed(1)\n",
    "kmeans_model = kmeans.fit(final_data)\n",
    "kmeans_pred = kmeans_model.transform(final_data)\n",
    "print('Clustering Results : \\n')\n",
    "kmeans_pred.show()\n",
    "cluster_centers = kmeans_model.clusterCenters()\n",
    "print('Cluster Centers : \\n{cluster_centers}')\n",
    "silhouette = kmeans_eval.evaluate(kmeans_pred)\n",
    "print(f'Silhouette with squared euclidean distance :{silhouette}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
