{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    master('local').\\\n",
    "    appName('tree-methods-basics').\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import (\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    GBTClassifier\n",
    ")\n",
    "from pyspark.ml.regression import (\n",
    "    DecisionTreeRegressor,\n",
    "    RandomForestRegressor,\n",
    "    GBTRegressor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format('libsvm').\\\n",
    "    load('D:/learn-ab/learning-PySpark/sample-data/sample-libsvm-data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfeaturesCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'features'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlabelCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpredictionCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprobabilityCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'probability'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrawPredictionCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rawPrediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmaxDepth\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmaxBins\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mminInstancesPerNode\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mminInfoGain\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmaxMemoryInMB\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcacheNodeIds\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcheckpointInterval\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mimpurity\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mweightCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mleafCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mminWeightFractionPerNode\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "`Decision tree <http://en.wikipedia.org/wiki/Decision_tree_learning>`_\n",
      "learning algorithm for classification.\n",
      "It supports both binary and multiclass labels, as well as both continuous and categorical\n",
      "features.\n",
      "\n",
      ".. versionadded:: 1.4.0\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from pyspark.ml.linalg import Vectors\n",
      ">>> from pyspark.ml.feature import StringIndexer\n",
      ">>> df = spark.createDataFrame([\n",
      "...     (1.0, Vectors.dense(1.0)),\n",
      "...     (0.0, Vectors.sparse(1, [], []))], [\"label\", \"features\"])\n",
      ">>> stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexed\")\n",
      ">>> si_model = stringIndexer.fit(df)\n",
      ">>> td = si_model.transform(df)\n",
      ">>> dt = DecisionTreeClassifier(maxDepth=2, labelCol=\"indexed\", leafCol=\"leafId\")\n",
      ">>> model = dt.fit(td)\n",
      ">>> model.getLabelCol()\n",
      "'indexed'\n",
      ">>> model.setFeaturesCol(\"features\")\n",
      "DecisionTreeClassificationModel...\n",
      ">>> model.numNodes\n",
      "3\n",
      ">>> model.depth\n",
      "1\n",
      ">>> model.featureImportances\n",
      "SparseVector(1, {0: 1.0})\n",
      ">>> model.numFeatures\n",
      "1\n",
      ">>> model.numClasses\n",
      "2\n",
      ">>> print(model.toDebugString)\n",
      "DecisionTreeClassificationModel...depth=1, numNodes=3...\n",
      ">>> test0 = spark.createDataFrame([(Vectors.dense(-1.0),)], [\"features\"])\n",
      ">>> model.predict(test0.head().features)\n",
      "0.0\n",
      ">>> model.predictRaw(test0.head().features)\n",
      "DenseVector([1.0, 0.0])\n",
      ">>> model.predictProbability(test0.head().features)\n",
      "DenseVector([1.0, 0.0])\n",
      ">>> result = model.transform(test0).head()\n",
      ">>> result.prediction\n",
      "0.0\n",
      ">>> result.probability\n",
      "DenseVector([1.0, 0.0])\n",
      ">>> result.rawPrediction\n",
      "DenseVector([1.0, 0.0])\n",
      ">>> result.leafId\n",
      "0.0\n",
      ">>> test1 = spark.createDataFrame([(Vectors.sparse(1, [0], [1.0]),)], [\"features\"])\n",
      ">>> model.transform(test1).head().prediction\n",
      "1.0\n",
      ">>> dtc_path = temp_path + \"/dtc\"\n",
      ">>> dt.save(dtc_path)\n",
      ">>> dt2 = DecisionTreeClassifier.load(dtc_path)\n",
      ">>> dt2.getMaxDepth()\n",
      "2\n",
      ">>> model_path = temp_path + \"/dtc_model\"\n",
      ">>> model.save(model_path)\n",
      ">>> model2 = DecisionTreeClassificationModel.load(model_path)\n",
      ">>> model.featureImportances == model2.featureImportances\n",
      "True\n",
      ">>> model.transform(test0).take(1) == model2.transform(test0).take(1)\n",
      "True\n",
      ">>> df3 = spark.createDataFrame([\n",
      "...     (1.0, 0.2, Vectors.dense(1.0)),\n",
      "...     (1.0, 0.8, Vectors.dense(1.0)),\n",
      "...     (0.0, 1.0, Vectors.sparse(1, [], []))], [\"label\", \"weight\", \"features\"])\n",
      ">>> si3 = StringIndexer(inputCol=\"label\", outputCol=\"indexed\")\n",
      ">>> si_model3 = si3.fit(df3)\n",
      ">>> td3 = si_model3.transform(df3)\n",
      ">>> dt3 = DecisionTreeClassifier(maxDepth=2, weightCol=\"weight\", labelCol=\"indexed\")\n",
      ">>> model3 = dt3.fit(td3)\n",
      ">>> print(model3.toDebugString)\n",
      "DecisionTreeClassificationModel...depth=1, numNodes=3...\n",
      "\u001b[1;31mInit docstring:\u001b[0m __init__(self, \\*, featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\",                  probabilityCol=\"probability\", rawPredictionCol=\"rawPrediction\",                  maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0,                  maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity=\"gini\",                  seed=None, weightCol=None, leafCol=\"\", minWeightFractionPerNode=0.0)\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\learn-ab\\learning-pyspark\\.env\\lib\\site-packages\\pyspark\\ml\\classification.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier()\n",
    "gb_clf = GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_clf_model = dc_clf.fit(train_data)\n",
    "rf_clf_model = rf_clf.fit(train_data)\n",
    "gb_clf_model = gb_clf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_clf_pred = dc_clf_model.transform(test_data)\n",
    "rf_clf_pred = rf_clf_model.transform(test_data)\n",
    "gb_clf_pred = gb_clf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|(692,[100,101,102...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[125,126,127...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[181,182,183...|   [32.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|   [0.0,36.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,36.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,36.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,36.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [0.0,36.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [0.0,36.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[125,126,127...|   [0.0,36.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[127,128,129...|   [0.0,36.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[128,129,155...|   [0.0,36.0]|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dc_clf_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|(692,[100,101,102...|   [15.0,5.0]|[0.75,0.25]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[125,126,127...|   [19.0,1.0]|[0.95,0.05]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[181,182,183...|   [18.0,2.0]|  [0.9,0.1]|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|   [4.0,16.0]|  [0.2,0.8]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,20.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [0.0,20.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|   [1.0,19.0]|[0.05,0.95]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [0.0,20.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [4.0,16.0]|  [0.2,0.8]|       1.0|\n",
      "|  1.0|(692,[125,126,127...|   [0.0,20.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[127,128,129...|   [0.0,20.0]|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[128,129,155...|   [0.0,20.0]|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[100,101,102...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[125,126,127...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[1.29370791752444...|[0.93004727978904...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  0.0|(692,[181,182,183...|[1.54350200272498...|[0.95635347857270...|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[125,126,127...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[127,128,129...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "|  1.0|(692,[128,129,155...|[-1.5435020027249...|[0.04364652142729...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_clf_pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpredictionCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlabelCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetricName\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'MulticlassClassificationEvaluatorMetricType'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mweightCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetricLabel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbeta\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprobabilityCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'probability'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0meps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Evaluator for Multiclass Classification, which expects input\n",
      "columns: prediction, label, weight (optional) and probabilityCol (only for logLoss).\n",
      "\n",
      ".. versionadded:: 1.5.0\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> scoreAndLabels = [(0.0, 0.0), (0.0, 1.0), (0.0, 0.0),\n",
      "...     (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (2.0, 2.0), (2.0, 0.0)]\n",
      ">>> dataset = spark.createDataFrame(scoreAndLabels, [\"prediction\", \"label\"])\n",
      ">>> evaluator = MulticlassClassificationEvaluator()\n",
      ">>> evaluator.setPredictionCol(\"prediction\")\n",
      "MulticlassClassificationEvaluator...\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.66...\n",
      ">>> evaluator.evaluate(dataset, {evaluator.metricName: \"accuracy\"})\n",
      "0.66...\n",
      ">>> evaluator.evaluate(dataset, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
      "...     evaluator.metricLabel: 1.0})\n",
      "0.75...\n",
      ">>> evaluator.setMetricName(\"hammingLoss\")\n",
      "MulticlassClassificationEvaluator...\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.33...\n",
      ">>> mce_path = temp_path + \"/mce\"\n",
      ">>> evaluator.save(mce_path)\n",
      ">>> evaluator2 = MulticlassClassificationEvaluator.load(mce_path)\n",
      ">>> str(evaluator2.getPredictionCol())\n",
      "'prediction'\n",
      ">>> scoreAndLabelsAndWeight = [(0.0, 0.0, 1.0), (0.0, 1.0, 1.0), (0.0, 0.0, 1.0),\n",
      "...     (1.0, 0.0, 1.0), (1.0, 1.0, 1.0), (1.0, 1.0, 1.0), (1.0, 1.0, 1.0),\n",
      "...     (2.0, 2.0, 1.0), (2.0, 0.0, 1.0)]\n",
      ">>> dataset = spark.createDataFrame(scoreAndLabelsAndWeight, [\"prediction\", \"label\", \"weight\"])\n",
      ">>> evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
      "...     weightCol=\"weight\")\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.66...\n",
      ">>> evaluator.evaluate(dataset, {evaluator.metricName: \"accuracy\"})\n",
      "0.66...\n",
      ">>> predictionAndLabelsWithProbabilities = [\n",
      "...      (1.0, 1.0, 1.0, [0.1, 0.8, 0.1]), (0.0, 2.0, 1.0, [0.9, 0.05, 0.05]),\n",
      "...      (0.0, 0.0, 1.0, [0.8, 0.2, 0.0]), (1.0, 1.0, 1.0, [0.3, 0.65, 0.05])]\n",
      ">>> dataset = spark.createDataFrame(predictionAndLabelsWithProbabilities, [\"prediction\",\n",
      "...     \"label\", \"weight\", \"probability\"])\n",
      ">>> evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
      "...     probabilityCol=\"probability\")\n",
      ">>> evaluator.setMetricName(\"logLoss\")\n",
      "MulticlassClassificationEvaluator...\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.9682...\n",
      "\u001b[1;31mInit docstring:\u001b[0m __init__(self, \\*, predictionCol=\"prediction\", labelCol=\"label\",                  metricName=\"f1\", weightCol=None, metricLabel=0.0, beta=1.0,                  probabilityCol=\"probability\", eps=1e-15)\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\learn-ab\\learning-pyspark\\.env\\lib\\site-packages\\pyspark\\ml\\evaluation.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(\n",
    "    metricName='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy     :  0.967741935483871\n",
      "Random Forest Accuracy     :  0.967741935483871\n",
      "Gradient Boosting Accuracy :  0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Accuracy     : \", acc_eval.evaluate(dc_clf_pred))\n",
    "print(\"Random Forest Accuracy     : \", acc_eval.evaluate(rf_clf_pred))\n",
    "print(\"Gradient Boosting Accuracy : \", acc_eval.evaluate(gb_clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(692, {100: 0.0565, 406: 0.9435})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_clf_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(692, {99: 0.0018, 237: 0.0023, 244: 0.0755, 263: 0.0145, 268: 0.0019, 272: 0.1033, 301: 0.0032, 344: 0.0029, 349: 0.0208, 352: 0.0114, 358: 0.0025, 375: 0.0121, 379: 0.0445, 398: 0.0166, 401: 0.0077, 406: 0.0547, 407: 0.0449, 413: 0.0311, 428: 0.035, 433: 0.1413, 434: 0.05, 435: 0.0171, 440: 0.0334, 457: 0.014, 460: 0.0017, 461: 0.0955, 463: 0.0527, 489: 0.0386, 490: 0.0052, 491: 0.0028, 496: 0.0027, 511: 0.0117, 539: 0.036, 572: 0.0027, 577: 0.0032, 665: 0.0045})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(692, {100: 0.0297, 267: 0.0068, 293: 0.0007, 320: 0.0023, 406: 0.5065, 433: 0.0688, 434: 0.2258, 490: 0.1424, 568: 0.017})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
