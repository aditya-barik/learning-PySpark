{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    master('local').\\\n",
    "    appName('logistic-regression-basics').\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format('libsvm').\\\n",
    "    load('D:/learn-ab/learning-PySpark/sample-data/sample-libsvm-data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = logreg.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_summary = logreg_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model_summary.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model_summary.predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[127,128,129...|[20.3777627514872...|[0.99999999858729...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-21.114014198868...|[6.76550380000486...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-23.743613234676...|[4.87842678716171...|       1.0|\n",
      "|  1.0|(692,[152,153,154...|[-19.192574012720...|[4.62137287298141...|       1.0|\n",
      "|  1.0|(692,[151,152,153...|[-20.125398874699...|[1.81823629113070...|       1.0|\n",
      "|  0.0|(692,[129,130,131...|[20.4890549504196...|[0.99999999873608...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-21.082940212814...|[6.97903542823781...|       1.0|\n",
      "|  1.0|(692,[99,100,101,...|[-19.622713503550...|[3.00582577446123...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[21.1594863606582...|[0.99999999935352...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[28.1036706837287...|[0.99999999999937...|       0.0|\n",
      "|  1.0|(692,[154,155,156...|[-21.054076780106...|[7.18340962960319...|       1.0|\n",
      "|  0.0|(692,[153,154,155...|[26.9648490510184...|[0.99999999999805...|       0.0|\n",
      "|  0.0|(692,[151,152,153...|[32.7855654161400...|[0.99999999999999...|       0.0|\n",
      "|  1.0|(692,[129,130,131...|[-20.331839179667...|[1.47908944089725...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[21.7830579106564...|[0.99999999965347...|       0.0|\n",
      "|  1.0|(692,[150,151,152...|[-20.640562103728...|[1.08621994880355...|       1.0|\n",
      "|  0.0|(692,[124,125,126...|[22.6400775503731...|[0.99999999985292...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[38.0712919910909...|           [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|[-19.830803265627...|[2.44113371545875...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-21.016054806036...|[7.46179590484091...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model_summary.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(692,[127,128,129,130,131,154,155,156,157,158,159,181,182,183,184,185,186,187,188,189,207,208,209,210,211,212,213,214,215,216,217,235,236,237,238,239,240,241,242,243,244,245,262,263,264,265,266,267,268,269,270,271,272,273,289,290,291,292,293,294,295,296,297,300,301,302,316,317,318,319,320,321,328,329,330,343,344,345,346,347,348,349,356,357,358,371,372,373,374,384,385,386,399,400,401,412,413,414,426,427,428,429,440,441,442,454,455,456,457,466,467,468,469,470,482,483,484,493,494,495,496,497,510,511,512,520,521,522,523,538,539,540,547,548,549,550,566,567,568,569,570,571,572,573,574,575,576,577,578,594,595,596,597,598,599,600,601,602,603,604,622,623,624,625,626,627,628,629,630,651,652,653,654,655,656,657],[51.0,159.0,253.0,159.0,50.0,48.0,238.0,252.0,252.0,252.0,237.0,54.0,227.0,253.0,252.0,239.0,233.0,252.0,57.0,6.0,10.0,60.0,224.0,252.0,253.0,252.0,202.0,84.0,252.0,253.0,122.0,163.0,252.0,252.0,252.0,253.0,252.0,252.0,96.0,189.0,253.0,167.0,51.0,238.0,253.0,253.0,190.0,114.0,253.0,228.0,47.0,79.0,255.0,168.0,48.0,238.0,252.0,252.0,179.0,12.0,75.0,121.0,21.0,253.0,243.0,50.0,38.0,165.0,253.0,233.0,208.0,84.0,253.0,252.0,165.0,7.0,178.0,252.0,240.0,71.0,19.0,28.0,253.0,252.0,195.0,57.0,252.0,252.0,63.0,253.0,252.0,195.0,198.0,253.0,190.0,255.0,253.0,196.0,76.0,246.0,252.0,112.0,253.0,252.0,148.0,85.0,252.0,230.0,25.0,7.0,135.0,253.0,186.0,12.0,85.0,252.0,223.0,7.0,131.0,252.0,225.0,71.0,85.0,252.0,145.0,48.0,165.0,252.0,173.0,86.0,253.0,225.0,114.0,238.0,253.0,162.0,85.0,252.0,249.0,146.0,48.0,29.0,85.0,178.0,225.0,253.0,223.0,167.0,56.0,85.0,252.0,252.0,252.0,229.0,215.0,252.0,252.0,252.0,196.0,130.0,28.0,199.0,252.0,252.0,253.0,252.0,252.0,233.0,145.0,25.0,128.0,252.0,253.0,252.0,141.0,37.0])\n",
      "[20.377762751487253,-20.377762751487253]\n",
      "[0.9999999985872996,1.4127004011044164e-09]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for item in logreg_model_summary.predictions.head(1)[0]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_2 = LogisticRegression()\n",
    "logreg_model_2 = logreg_2.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_and_labels = logreg_model_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|[30.4838258018209...|[0.99999999999994...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[50.0626771777086...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[40.3791533076966...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[43.1549243548129...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[24.2073736826804...|[0.99999999996931...|       0.0|\n",
      "|  0.0|(692,[125,126,127...|[32.9401966713895...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[36.1417644179509...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[24.3415938286769...|[0.99999999997317...|       0.0|\n",
      "|  0.0|(692,[150,151,152...|[26.9172819365379...|[0.99999999999795...|       0.0|\n",
      "|  0.0|(692,[151,152,153...|[41.2861638726489...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[43.5701601910591...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[22.1744720393951...|[0.99999999976571...|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[27.2186286877769...|[0.99999999999848...|       0.0|\n",
      "|  0.0|(692,[155,156,180...|[45.0549068030275...|           [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[123,124,125...|[-22.547216256587...|[1.61386943807852...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-23.224772660117...|[8.19614041801322...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-20.946416075358...|[7.99994649699209...|       1.0|\n",
      "|  1.0|(692,[127,128,155...|[-21.969561572183...|[2.87568054479222...|       1.0|\n",
      "|  1.0|(692,[128,129,130...|[-20.030195223294...|[1.99984686804633...|       1.0|\n",
      "|  1.0|(692,[128,129,130...|[-20.942212902373...|[8.03364242125561...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import (\n",
    "    BinaryClassificationEvaluator,\n",
    "    MulticlassClassificationEvaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrawPredictionCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rawPrediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlabelCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetricName\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'BinaryClassificationEvaluatorMetricType'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'areaUnderROC'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mweightCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnumBins\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Evaluator for binary classification, which expects input columns rawPrediction, label\n",
      "and an optional weight column.\n",
      "The rawPrediction column can be of type double (binary 0/1 prediction, or probability of label\n",
      "1) or of type vector (length-2 vector of raw predictions, scores, or label probabilities).\n",
      "\n",
      ".. versionadded:: 1.4.0\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from pyspark.ml.linalg import Vectors\n",
      ">>> scoreAndLabels = map(lambda x: (Vectors.dense([1.0 - x[0], x[0]]), x[1]),\n",
      "...    [(0.1, 0.0), (0.1, 1.0), (0.4, 0.0), (0.6, 0.0), (0.6, 1.0), (0.6, 1.0), (0.8, 1.0)])\n",
      ">>> dataset = spark.createDataFrame(scoreAndLabels, [\"raw\", \"label\"])\n",
      "...\n",
      ">>> evaluator = BinaryClassificationEvaluator()\n",
      ">>> evaluator.setRawPredictionCol(\"raw\")\n",
      "BinaryClassificationEvaluator...\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.70...\n",
      ">>> evaluator.evaluate(dataset, {evaluator.metricName: \"areaUnderPR\"})\n",
      "0.83...\n",
      ">>> bce_path = temp_path + \"/bce\"\n",
      ">>> evaluator.save(bce_path)\n",
      ">>> evaluator2 = BinaryClassificationEvaluator.load(bce_path)\n",
      ">>> str(evaluator2.getRawPredictionCol())\n",
      "'raw'\n",
      ">>> scoreAndLabelsAndWeight = map(lambda x: (Vectors.dense([1.0 - x[0], x[0]]), x[1], x[2]),\n",
      "...    [(0.1, 0.0, 1.0), (0.1, 1.0, 0.9), (0.4, 0.0, 0.7), (0.6, 0.0, 0.9),\n",
      "...     (0.6, 1.0, 1.0), (0.6, 1.0, 0.3), (0.8, 1.0, 1.0)])\n",
      ">>> dataset = spark.createDataFrame(scoreAndLabelsAndWeight, [\"raw\", \"label\", \"weight\"])\n",
      "...\n",
      ">>> evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"raw\", weightCol=\"weight\")\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.70...\n",
      ">>> evaluator.evaluate(dataset, {evaluator.metricName: \"areaUnderPR\"})\n",
      "0.82...\n",
      ">>> evaluator.getNumBins()\n",
      "1000\n",
      "\u001b[1;31mInit docstring:\u001b[0m __init__(self, \\*, rawPredictionCol=\"rawPrediction\", labelCol=\"label\",                  metricName=\"areaUnderROC\", weightCol=None, numBins=1000)\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\learn-ab\\learning-pyspark\\.env\\lib\\site-packages\\pyspark\\ml\\evaluation.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_evaluator = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_roc = bin_evaluator.evaluate(pred_and_labels.predictions)\n",
    "bin_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mMulticlassClassificationEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpredictionCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'prediction'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mlabelCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetricName\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'MulticlassClassificationEvaluatorMetricType'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mweightCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmetricLabel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbeta\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprobabilityCol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'probability'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0meps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Evaluator for Multiclass Classification, which expects input\n",
      "columns: prediction, label, weight (optional) and probabilityCol (only for logLoss).\n",
      "\n",
      ".. versionadded:: 1.5.0\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> scoreAndLabels = [(0.0, 0.0), (0.0, 1.0), (0.0, 0.0),\n",
      "...     (1.0, 0.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (2.0, 2.0), (2.0, 0.0)]\n",
      ">>> dataset = spark.createDataFrame(scoreAndLabels, [\"prediction\", \"label\"])\n",
      ">>> evaluator = MulticlassClassificationEvaluator()\n",
      ">>> evaluator.setPredictionCol(\"prediction\")\n",
      "MulticlassClassificationEvaluator...\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.66...\n",
      ">>> evaluator.evaluate(dataset, {evaluator.metricName: \"accuracy\"})\n",
      "0.66...\n",
      ">>> evaluator.evaluate(dataset, {evaluator.metricName: \"truePositiveRateByLabel\",\n",
      "...     evaluator.metricLabel: 1.0})\n",
      "0.75...\n",
      ">>> evaluator.setMetricName(\"hammingLoss\")\n",
      "MulticlassClassificationEvaluator...\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.33...\n",
      ">>> mce_path = temp_path + \"/mce\"\n",
      ">>> evaluator.save(mce_path)\n",
      ">>> evaluator2 = MulticlassClassificationEvaluator.load(mce_path)\n",
      ">>> str(evaluator2.getPredictionCol())\n",
      "'prediction'\n",
      ">>> scoreAndLabelsAndWeight = [(0.0, 0.0, 1.0), (0.0, 1.0, 1.0), (0.0, 0.0, 1.0),\n",
      "...     (1.0, 0.0, 1.0), (1.0, 1.0, 1.0), (1.0, 1.0, 1.0), (1.0, 1.0, 1.0),\n",
      "...     (2.0, 2.0, 1.0), (2.0, 0.0, 1.0)]\n",
      ">>> dataset = spark.createDataFrame(scoreAndLabelsAndWeight, [\"prediction\", \"label\", \"weight\"])\n",
      ">>> evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
      "...     weightCol=\"weight\")\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.66...\n",
      ">>> evaluator.evaluate(dataset, {evaluator.metricName: \"accuracy\"})\n",
      "0.66...\n",
      ">>> predictionAndLabelsWithProbabilities = [\n",
      "...      (1.0, 1.0, 1.0, [0.1, 0.8, 0.1]), (0.0, 2.0, 1.0, [0.9, 0.05, 0.05]),\n",
      "...      (0.0, 0.0, 1.0, [0.8, 0.2, 0.0]), (1.0, 1.0, 1.0, [0.3, 0.65, 0.05])]\n",
      ">>> dataset = spark.createDataFrame(predictionAndLabelsWithProbabilities, [\"prediction\",\n",
      "...     \"label\", \"weight\", \"probability\"])\n",
      ">>> evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
      "...     probabilityCol=\"probability\")\n",
      ">>> evaluator.setMetricName(\"logLoss\")\n",
      "MulticlassClassificationEvaluator...\n",
      ">>> evaluator.evaluate(dataset)\n",
      "0.9682...\n",
      "\u001b[1;31mInit docstring:\u001b[0m __init__(self, \\*, predictionCol=\"prediction\", labelCol=\"label\",                  metricName=\"f1\", weightCol=None, metricLabel=0.0, beta=1.0,                  probabilityCol=\"probability\", eps=1e-15)\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\learn-ab\\learning-pyspark\\.env\\lib\\site-packages\\pyspark\\ml\\evaluation.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_evaluator = MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_f1 = mul_evaluator.evaluate(pred_and_labels.predictions)\n",
    "mul_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
